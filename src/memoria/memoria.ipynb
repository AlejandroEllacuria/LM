{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "67037863",
      "metadata": {},
      "source": [
        "# Memoria del proyecto — Predicción de enfermedad cardíaca (Heart Failure Prediction)\n",
        "\n",
        "**Autor/a:** Alex Ellakuria\n",
        "**Fecha:** 2025-12-26  \n",
        "\n",
        "Este notebook funciona como **memoria ejecutable** del proyecto: recoge el objetivo, los datos, el EDA, el preprocesado, el entrenamiento de modelos, la evaluación y las conclusiones, con un enfoque claro y defendible a nivel de máster."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c287dce",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Objetivo del proyecto\n",
        "\n",
        "El objetivo es **predecir el riesgo de enfermedad cardíaca** (`enfermedad_cardiaca`) a partir de variables clínicas y demográficas.\n",
        "\n",
        "- **Tipo de problema:** Clasificación binaria.\n",
        "- **Variable objetivo:** `enfermedad_cardiaca` (1 = enfermedad, 0 = no enfermedad).\n",
        "- **Uso esperado (impacto):** priorización de pacientes para cribado/seguimiento clínico y apoyo a decisiones médicas (no sustitución del diagnóstico)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a71f33a0",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Dataset\n",
        "\n",
        "Se utiliza el dataset **Heart Failure Prediction** (Kaggle / UCI combinados), con aproximadamente **918 observaciones** tras limpieza del autor original.\n",
        "\n",
        "### Variables (resumen)\n",
        "- Numéricas: edad, presión en reposo, colesterol, frecuencia cardiaca máxima, oldpeak...\n",
        "- Categóricas: sexo, tipo de dolor en el pecho, ECG en reposo, angina inducida por ejercicio, pendiente ST...\n",
        "- Binaria: glucosa en ayunas > 120 mg/dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8dd7bea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 0) Imports + configuración\n",
        "# =========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score, confusion_matrix,\n",
        "    RocCurveDisplay, PrecisionRecallDisplay\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "DATA_PATH = \"data/heart.csv\"\n",
        "TARGET_RAW = \"HeartDisease\"\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams.update({\n",
        "    \"figure.dpi\": 110,\n",
        "    \"axes.titlesize\": 14,\n",
        "    \"axes.labelsize\": 12,\n",
        "    \"xtick.labelsize\": 10,\n",
        "    \"ytick.labelsize\": 10\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd75aa26",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Carga, renombrado y diccionario de etiquetas\n",
        "\n",
        "Trabajo con nombres de columnas en español para mejorar claridad y consistencia en el informe y los gráficos.\n",
        "Además, uso un diccionario `LABELS` **solo para etiquetar gráficos** (sin cambiar datos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6e1c23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 1) Carga + renombrado\n",
        "# =========================\n",
        "df_raw = pd.read_csv(DATA_PATH)\n",
        "\n",
        "RENAME = {\n",
        "    \"Age\": \"edad\",\n",
        "    \"Sex\": \"sexo\",\n",
        "    \"ChestPainType\": \"tipo_dolor_pecho\",\n",
        "    \"RestingBP\": \"presion_reposo\",\n",
        "    \"Cholesterol\": \"colesterol\",\n",
        "    \"FastingBS\": \"glucosa_ayunas\",\n",
        "    \"RestingECG\": \"ecg_reposo\",\n",
        "    \"MaxHR\": \"fc_max\",\n",
        "    \"ExerciseAngina\": \"angina_ejercicio\",\n",
        "    \"Oldpeak\": \"oldpeak\",\n",
        "    \"ST_Slope\": \"pendiente_st\",\n",
        "    \"HeartDisease\": \"enfermedad_cardiaca\"\n",
        "}\n",
        "df = df_raw.rename(columns=RENAME).copy()\n",
        "TARGET = RENAME.get(TARGET_RAW, TARGET_RAW)\n",
        "\n",
        "LABELS = {\n",
        "    \"edad\": \"Edad del paciente (años)\",\n",
        "    \"sexo\": \"Sexo\",\n",
        "    \"tipo_dolor_pecho\": \"Tipo de dolor en el pecho\",\n",
        "    \"presion_reposo\": \"Presión arterial en reposo (mm Hg)\",\n",
        "    \"colesterol\": \"Colesterol sérico (mg/dl)\",\n",
        "    \"glucosa_ayunas\": \"Glucosa en ayunas > 120 mg/dl\",\n",
        "    \"ecg_reposo\": \"Electrocardiograma en reposo\",\n",
        "    \"fc_max\": \"Frecuencia cardíaca máxima alcanzada\",\n",
        "    \"angina_ejercicio\": \"Angina inducida por ejercicio\",\n",
        "    \"oldpeak\": \"Depresión del segmento ST (oldpeak)\",\n",
        "    \"pendiente_st\": \"Pendiente del segmento ST\",\n",
        "    \"enfermedad_cardiaca\": \"Enfermedad cardíaca\"\n",
        "}\n",
        "\n",
        "def label(col: str) -> str:\n",
        "    return LABELS.get(col, col)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97378fa8",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Split train/test (evitar leakage)\n",
        "\n",
        "Primero divido en entrenamiento y test **antes** de decisiones de preprocesado/modelado.  \n",
        "Esto hace que las conclusiones sean defendibles y evita contaminación del test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9c1586",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e1faaf4",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. EDA (resumen ejecutable)\n",
        "\n",
        "En esta sección recojo lo esencial del EDA:\n",
        "- Distribución del target\n",
        "- Revisión de numéricas (distribución por clase)\n",
        "- Correlación numérica (solo para exploración)\n",
        "\n",
        "> Nota: La correlación Pearson no “mide importancia”, pero ayuda a ver relaciones lineales y redundancias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ed5a81",
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_cols = [\"sexo\", \"tipo_dolor_pecho\", \"ecg_reposo\", \"angina_ejercicio\", \"pendiente_st\"]\n",
        "binary_cols = [\"glucosa_ayunas\"]\n",
        "numeric_cols = [\"edad\", \"presion_reposo\", \"colesterol\", \"fc_max\", \"oldpeak\"]\n",
        "\n",
        "# Distribución del target\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.countplot(x=y_train)\n",
        "plt.title(\"Distribución del target en train\")\n",
        "plt.xlabel(label(TARGET))\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61b5a4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlación (numéricas + binaria + target) en train\n",
        "num_df = pd.concat([X_train[numeric_cols + binary_cols], y_train.rename(TARGET)], axis=1).copy()\n",
        "\n",
        "# Trato ceros sospechosos como NaN en columnas típicas (criterio clínico / plausibilidad)\n",
        "for c in [\"presion_reposo\", \"colesterol\", \"fc_max\"]:\n",
        "    if c in num_df.columns:\n",
        "        num_df[c] = num_df[c].replace(0, np.nan)\n",
        "\n",
        "corr = num_df.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=0.5, square=True)\n",
        "plt.title(\"Matriz de correlación (train: numéricas + target)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96cdb179",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Preparación para Machine Learning\n",
        "\n",
        "### 6.1. Diseño del preprocesado\n",
        "- **Numéricas:** imputación simple (mediana) + escalado (útil para modelos lineales y SVM).\n",
        "- **Categóricas:** One-Hot Encoding.\n",
        "- **Binarias:** se tratan como numéricas (0/1).\n",
        "\n",
        "> Mantengo todo dentro de un **Pipeline** para evitar leakage y facilitar reproducibilidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2ed569",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "numeric_features = numeric_cols + binary_cols\n",
        "categorical_features = categorical_cols\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline(steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        (\"cat\", Pipeline(steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "        ]), categorical_features),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741c20fa",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Modelos candidatos y métricas de comparación\n",
        "\n",
        "Comparo varios modelos con métricas adecuadas al problema:\n",
        "\n",
        "- **ROC-AUC:** capacidad de ranking global.\n",
        "- **Average Precision (PR-AUC):** útil cuando importa el positivo (riesgo).\n",
        "- **F1 / Recall:** relevantes si priorizo detectar casos (sensibilidad).\n",
        "\n",
        "> En salud suele interesar **recall alto** (reducir falsos negativos), ajustando según el contexto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f644cd1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "models = {\n",
        "    \"LogReg\": LogisticRegression(max_iter=2000, random_state=RANDOM_STATE),\n",
        "    \"SVM_RBF\": SVC(probability=True, random_state=RANDOM_STATE),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
        "}\n",
        "\n",
        "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
        "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, \"predict_proba\") else None\n",
        "\n",
        "    metrics = {\n",
        "        \"modelo\": name,\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "    }\n",
        "    if y_proba is not None:\n",
        "        metrics[\"roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
        "        metrics[\"avg_precision\"] = average_precision_score(y_test, y_proba)\n",
        "    else:\n",
        "        metrics[\"roc_auc\"] = np.nan\n",
        "        metrics[\"avg_precision\"] = np.nan\n",
        "\n",
        "    return pipe, metrics\n",
        "\n",
        "results = []\n",
        "fitted = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe, m = evaluate_model(name, model, X_train, y_train, X_test, y_test)\n",
        "    fitted[name] = pipe\n",
        "    results.append(m)\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values([\"roc_auc\", \"avg_precision\"], ascending=False)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79474b30",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Selección del modelo final y evaluación visual\n",
        "\n",
        "Reviso:\n",
        "- ROC y PR curves\n",
        "- Matriz de confusión\n",
        "\n",
        "(Después, si el contexto lo requiere, ajusto el umbral para aumentar recall.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c5aca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_name = results_df.iloc[0][\"modelo\"]\n",
        "best_pipe = fitted[best_name]\n",
        "\n",
        "y_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
        "plt.title(f\"ROC — {best_name}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "PrecisionRecallDisplay.from_predictions(y_test, y_proba)\n",
        "plt.title(f\"Precision-Recall — {best_name}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "y_pred = (y_proba >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
        "plt.title(f\"Matriz de confusión (umbral 0.5) — {best_name}\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "265e0974",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 9. Guardado del modelo final (pickle)\n",
        "\n",
        "Guardo el pipeline completo (preprocesado + modelo).  \n",
        "Esto permite reutilizarlo directamente en producción o para inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d446de",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "MODEL_DIR = Path(\"model\") / \"production\"\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "final_model_file = MODEL_DIR / f\"modelo_final_{best_name}.pkl\"\n",
        "\n",
        "with open(final_model_file, \"wb\") as f:\n",
        "    pickle.dump(best_pipe, f)\n",
        "\n",
        "final_model_file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b80b482",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 10. Conclusiones\n",
        "\n",
        "- Pipeline reproducible y sin leakage.\n",
        "- Comparación de múltiples modelos con métricas adecuadas.\n",
        "- Elección final basada en métricas + análisis de errores.\n",
        "- Modelo exportado para reutilización.\n",
        "\n",
        "### Próximos pasos recomendados (nivel máster)\n",
        "- Validación cruzada y búsqueda de hiperparámetros (GridSearch/Randomized).\n",
        "- Interpretabilidad (coeficientes / SHAP según el modelo).\n",
        "- Calibración de probabilidades y ajuste de umbral según coste de errores."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
